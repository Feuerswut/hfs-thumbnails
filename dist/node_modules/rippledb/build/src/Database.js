"use strict";

exports.__esModule = true;
exports.default = void 0;

var _DBHelper = require("./DBHelper");

var _MemTable = _interopRequireDefault(require("./MemTable"));

var _LogWriter = _interopRequireDefault(require("./LogWriter"));

var _Options = require("./Options");

var _IteratorHelper = _interopRequireDefault(require("./IteratorHelper"));

var _Format = require("./Format");

var _VersionFormat = require("./VersionFormat");

var _Compaction = require("./Compaction");

var _Slice = _interopRequireDefault(require("./Slice"));

var _VersionSet = _interopRequireDefault(require("./VersionSet"));

var _VersionEdit = _interopRequireDefault(require("./VersionEdit"));

var _VersionEditRecord = _interopRequireDefault(require("./VersionEditRecord"));

var _Filename = require("./Filename");

var _WriteBatch = require("./WriteBatch");

var _Status = _interopRequireDefault(require("./Status"));

var _SSTableBuilder = _interopRequireDefault(require("./SSTableBuilder"));

var _Comparator = require("./Comparator");

var _SSTableCache = require("./SSTableCache");

var _Snapshot = require("./Snapshot");

var _LogReader = _interopRequireDefault(require("./LogReader"));

var _Merger = _interopRequireDefault(require("./Merger"));

var _WriterQueue = require("./WriterQueue");

var _Lockfile = require("./Lockfile");

var _Builder = require("./Builder");

function _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }

function _defineProperty(obj, key, value) { if (key in obj) { Object.defineProperty(obj, key, { value: value, enumerable: true, configurable: true, writable: true }); } else { obj[key] = value; } return obj; }

const kNumNonTableCacheFiles = 10;

function getTableCacheSize(sanitizedOptions) {
  // Reserve ten files or so for other uses and give the rest to TableCache.
  return sanitizedOptions.maxOpenFiles - kNumNonTableCacheFiles;
}

class Database {
  constructor(dbpath, options = {}) {
    _defineProperty(this, "writers", new _WriterQueue.WriterQueue());

    _defineProperty(this, "tmpBatch", new _WriteBatch.WriteBatch());

    _defineProperty(this, "_internalKeyComparator", void 0);

    _defineProperty(this, "_backgroundCompactionScheduled", void 0);

    _defineProperty(this, "_dbpath", void 0);

    _defineProperty(this, "_sn", void 0);

    _defineProperty(this, "_ok", false);

    _defineProperty(this, "_status", void 0);

    _defineProperty(this, "_log", void 0);

    _defineProperty(this, "_logFileNumber", 0);

    _defineProperty(this, "_memtable", void 0);

    _defineProperty(this, "_immtable", void 0);

    _defineProperty(this, "_versionSet", void 0);

    _defineProperty(this, "_manualCompaction", void 0);

    _defineProperty(this, "_bgError", void 0);

    _defineProperty(this, "pendingOutputs", void 0);

    _defineProperty(this, "_snapshots", void 0);

    _defineProperty(this, "_stats", void 0);

    _defineProperty(this, "_options", void 0);

    _defineProperty(this, "_tableCache", void 0);

    _defineProperty(this, "lockfile", void 0);

    if (!options.env) throw new Error("env required");
    const env = options.env;
    this._backgroundCompactionScheduled = false;
    this._internalKeyComparator = new _Format.InternalKeyComparator(new _Comparator.BytewiseComparator());
    this._dbpath = dbpath; // this._memtable = new MemTable(this._internalKeyComparator)

    this._sn = 0n;
    this.pendingOutputs = new Set();
    this._stats = Array.from({
      length: _Format.Config.kNumLevels
    }, () => new _Compaction.CompactionStats());
    options.comparator = this._internalKeyComparator;
    this._options = { ..._Options.defaultOptions,
      ...options,
      env
    };
    this.lockfile = new _Lockfile.Lockfile((0, _Filename.getLockFilename)(dbpath), this._options);
    this._tableCache = new _SSTableCache.TableCache(dbpath, this._options, getTableCacheSize(this._options));
    this._versionSet = new _VersionSet.default(this._dbpath, this._options, this._tableCache, this._internalKeyComparator);
    this._status = new _Status.default(this.recoverWrapper());
    this._snapshots = new _Snapshot.SnapshotList();
  }

  get userComparator() {
    return this._internalKeyComparator.userComparator;
  }

  async shouldInit() {
    const currentName = (0, _Filename.getCurrentFilename)(this._dbpath);
    let should = false;

    try {
      await this._options.env.access(this._dbpath);
    } catch (e) {
      should = true;
      await this._options.env.mkdir(this._dbpath);
    }

    await this.lockfile.lock();

    try {
      await this._options.env.access(currentName);
    } catch (e) {
      should = true;
    }

    return should;
  } // new db


  async initVersionEdit() {
    const edit = new _VersionEdit.default();
    edit.comparator = this._internalKeyComparator.userComparator.getName();
    edit.logNumber = 0;
    edit.nextFileNumber = 2;
    edit.lastSequence = 0n;
    const writer = new _LogWriter.default(await this._options.env.open((0, _Filename.getManifestFilename)(this._dbpath, 1), "a"));
    await writer.addRecord(_VersionEditRecord.default.add(edit));
    await writer.close();
    await this._options.env.writeFile((0, _Filename.getCurrentFilename)(this._dbpath), "MANIFEST-000001\n");
  }

  async recoverWrapper() {
    try {
      let status = new _Status.default(this.recover());
      let edit = {};
      let saveManifest = false;

      if (await status.ok()) {
        const result = await status.promise;
        edit = result.edit;
        saveManifest = result.saveManifest;
      } else {
        throw status.error;
      }

      if ((await status.ok()) && !this._memtable) {
        // Create new log and a corresponding memtable.
        const newLogNumber = this._versionSet.getNextFileNumber();

        edit.logNumber = newLogNumber;
        this._logFileNumber = newLogNumber;

        if (!!this._log) {
          await this._log.close();
          delete this._log;
        }

        this._log = new _LogWriter.default(await this._options.env.open((0, _Filename.getLogFilename)(this._dbpath, newLogNumber), "a"));
        this._memtable = new _MemTable.default(this._internalKeyComparator);

        this._memtable.ref();
      }

      if ((await status.ok()) && saveManifest) {
        edit.prevLogNumber = 0; // No older logs needed after recovery.

        edit.logNumber = this._logFileNumber;
        status = await this._versionSet.logAndApply(edit);
      }

      if (await status.ok()) {
        await this.deleteObsoleteFiles();
        await this.maybeScheduleCompaction();
        (0, _DBHelper.assert)(!!this._memtable);
      }

      if (!(await status.ok())) {
        throw status.error;
      }
    } catch (e) {
      if (this._options.debug) {
        this._options.log(`DEBUG DB recover fail`);
      }

      throw e;
    }
  }

  async recover() {
    const result = {
      saveManifest: false,
      edit: new _VersionEdit.default()
    };

    if (await this.shouldInit()) {
      await this.initVersionEdit();
    } else {
      try {
        await this._options.env.rename((0, _Filename.getInfoLogFilename)(this._dbpath), (0, _Filename.getOldInfoLogFilename)(this._dbpath));
      } catch (e) {}
    }

    this._options.infoLog = await this._options.env.open((0, _Filename.getInfoLogFilename)(this._dbpath), "a+");
    const versionSetRecoverResult = await this._versionSet.recover();

    if (typeof versionSetRecoverResult.saveManifest === "boolean") {
      result.saveManifest = versionSetRecoverResult.saveManifest;
    }

    const maxSequenceWrapper = {
      sequence: 0n
    }; // Recover from all newer log files than the ones named in the
    // descriptor (new log files may have been added by the previous
    // incarnation without registering them in the descriptor).
    //
    // Note that PrevLogNumber() is no longer used, but we pay
    // attention to it in case we are recovering a database
    // produced by an older version of leveldb.

    const minLog = this._versionSet.logNumber;
    const prevLog = this._versionSet.prevLogNumber;
    const filenames = (await this._options.env.readdir(this._dbpath)).reduce((filenames, dirent) => {
      if (dirent.isFile()) {
        filenames.push(dirent.name);
      }

      return filenames;
    }, []);
    const expected = new Set();

    this._versionSet.addLiveFiles(expected);

    let logs = [];

    for (const filename of filenames) {
      const internalFile = (0, _Filename.parseFilename)(filename);

      if (internalFile.isInternalFile) {
        expected.delete(internalFile.number);

        if (internalFile.type == _Format.FileType.kLogFile && (internalFile.number >= minLog || internalFile.number === prevLog)) {
          logs.push(internalFile.number);
        }
      }
    }

    if (expected.size > 0) {
      throw new Error(`${expected.size} missing files; e.g.`);
    }

    const edit = result.edit; // Recover in the order in which the logs were generated

    logs = logs.sort();

    for (let i = 0; i < logs.length; i++) {
      const result2 = await this.recoverLogFile(logs[i], i === logs.length - 1, edit, maxSequenceWrapper);

      if (typeof result2.saveManifest === "boolean") {
        result.saveManifest = result2.saveManifest;
      } // The previous incarnation may not have written any MANIFEST
      // records after allocating this log number.  So we manually
      // update the file number allocation counter in VersionSet.


      this._versionSet.markFileNumberUsed(logs[i]);
    }

    if (this._versionSet.lastSequence < maxSequenceWrapper.sequence) {
      this._versionSet.lastSequence = maxSequenceWrapper.sequence;
    }

    return result;
  }

  async recoverLogFile(logNumber, isLastLog, edit, maxSequenceWrapper) {
    const result = {};
    let status = new _Status.default(); // Open the log file

    const logFilename = (0, _Filename.getLogFilename)(this._dbpath, logNumber);
    const reader = new _LogReader.default(await this._options.env.open(logFilename, "r"));

    this._options.log(`Recovering log #${logNumber}`);

    let compactions = 0;
    let mem = null;

    for await (const record of reader.iterator()) {
      if (record.size < 12) {
        this._options.log(` ${logFilename} log record too small: dropping ${record.size} bytes`);

        continue;
      }

      const batch = new _WriteBatch.WriteBatch();

      _WriteBatch.WriteBatchInternal.setContents(batch, record.buffer);

      if (!mem) {
        mem = new _MemTable.default(this._internalKeyComparator);
        mem.ref();
      }

      _WriteBatch.WriteBatchInternal.insert(batch, mem);

      const lastSeq = _WriteBatch.WriteBatchInternal.getSequence(batch) + BigInt(_WriteBatch.WriteBatchInternal.getCount(batch)) - 1n;

      if (lastSeq > maxSequenceWrapper.sequence) {
        // TODO should not mutate argument
        maxSequenceWrapper.sequence = lastSeq;
      }

      if (mem.size > this._options.writeBufferSize) {
        compactions++;
        result.saveManifest = true;
        status = await this.writeLevel0Table(mem, edit);
        mem.unref();
        mem = null;

        if (!(await status.ok())) {
          break;
        }
      }
    }

    if (this._options.reuseLogs && isLastLog && compactions === 0) {// TODO
    }

    if (!!mem) {
      // mem did not get reused; compact it.
      if (await status.ok()) {
        result.saveManifest = true;
        status = await this.writeLevel0Table(mem, edit);
      }

      mem.unref();
    }

    return result;
  } // wait for db.recover


  async ok() {
    if (await this._status.ok()) {
      this._ok = true;
      return true;
    } else {
      this._ok = false;
      throw this._status.error;
    }
  }

  async close() {
    await this.lockfile.unlock();

    if (this._options.infoLog) {
      await this._options.infoLog.close();
    }

    if (this._log) {
      this._log.close();
    }

    await this._tableCache.destroy();
  }

  async *iterator(options = {}) {
    if (!this._ok) await this.ok();
    const sequence = options.snapshot ? options.snapshot.sequenceNumber : this._versionSet.lastSequence;
    const iteratorOptions = { ..._Options.defaultIteratorOptions,
      ...options
    };
    const reverse = iteratorOptions.reverse;
    const startUserKey = new _Slice.default(iteratorOptions.start);
    const lookupKey = new _Format.LookupKey(startUserKey, sequence);
    let lookupKeyUpdated = false;
    const iteratorList = [];

    this._memtable.ref();

    iteratorList.push(_IteratorHelper.default.wrap(_IteratorHelper.default.makeAsync(this._memtable.iterator(reverse)), () => {
      this._memtable.unref();
    }));

    if (this._immtable) {
      this._immtable.ref();

      iteratorList.push(_IteratorHelper.default.wrap(_IteratorHelper.default.makeAsync(this._immtable.iterator(reverse)), () => {
        this._immtable.unref();
      }));
    }

    const current = this._versionSet.current;
    const tableCache = this._versionSet.tableCache;
    current.ref();

    for (let i = 0; i < _Format.Config.kNumLevels; i++) {
      const files = current.files[i];

      if (files.length > 0) {
        for (const file of files) {
          // TODO change compare condition when reserve=true
          const shouldSkip = reverse ? this.userComparator.compare(startUserKey, file.smallest.userKey) < 0 : this.userComparator.compare(startUserKey, file.largest.userKey) > 0;
          if (shouldSkip) continue;
          const status = await tableCache.findTable(file.number, file.fileSize);

          if (await status.ok()) {
            file.refs++;
            const tf = await status.promise;
            iteratorList.push(_IteratorHelper.default.wrap(tf.table.entryIterator(reverse), async () => {
              file.refs--;
              current.unref();
              await tf.file.close();
            }));
          }
        }
      }
    }

    const merger = new _Merger.default(this._internalKeyComparator, iteratorList, iteratorList.length);

    for await (const entry of merger.iterator(reverse)) {
      const iKey = _Format.InternalKey.from(entry.key);

      const userKey = iKey.userKey;

      if (reverse) {
        if (!lookupKeyUpdated || this.userComparator.compare(userKey, lookupKey.userKey) < 0) {
          lookupKeyUpdated = true;
          lookupKey.userKey = userKey;
          if (iKey.type === _Format.ValueType.kTypeDeletion) continue;
          yield {
            key: userKey.buffer,
            value: entry.value.buffer
          };
        }
      } else {
        if (this.userComparator.compare(userKey, lookupKey.userKey) > 0) {
          lookupKey.userKey = userKey;
          if (iKey.type === _Format.ValueType.kTypeDeletion) continue;
          yield {
            key: userKey.buffer,
            value: entry.value.buffer
          };
        }
      }
    }
  }
  /**
   * db.get -> memtable.get -> imm.get -> versionCurrent.get ->
   * versionCurrent.forEachOverlapping -> tableCache.get -> tableCache.findTable ->
   * table.get
   */


  async get(userKey, options = {}) {
    if (!this._ok) await this.ok();
    const slicedUserKey = new _Slice.default(userKey);
    const sequence = options.snapshot ? options.snapshot.sequenceNumber : this._versionSet.lastSequence;
    const lookupKey = new _Format.LookupKey(slicedUserKey, sequence);
    const current = this._versionSet.current;

    this._memtable.ref();

    if (!!this._immtable) this._immtable.ref();
    current.ref();
    let hasStatUpdate = false;
    const stats = {};
    let result = undefined;

    while (true) {
      const memResult = this._memtable.get(lookupKey);

      if (!!memResult) {
        if (memResult.type === _Format.ValueType.kTypeValue) {
          result = memResult.value.buffer;
        } else {
          break;
        }
      }

      if (!result && !!this._immtable) {
        const immResult = this._immtable.get(lookupKey);

        if (!!immResult) {
          if (immResult.type === _Format.ValueType.kTypeValue) {
            result = immResult.value.buffer;
          } else {
            break;
          }
        }
      }

      if (!result) {
        const s = await current.get(lookupKey, stats);
        hasStatUpdate = true;

        if (await s.ok()) {
          result = await s.promise;
        }
      }

      break;
    }

    if (hasStatUpdate && current.updateStats(stats)) {
      await this.maybeScheduleCompaction();
    }

    this._memtable.unref();

    if (!!this._immtable) this._immtable.unref();
    current.unref();
    return result;
  }
  /**
   * TODO Trigger minor compaction's condition
   * 1. check if memtable bigger then 4mb
   * 2. check if this._immtable is not null（transfer memtable to sstable）
   */


  put(key, value, options) {
    const batch = new _WriteBatch.WriteBatch();
    batch.put(key, value);
    const writeOptions = { ..._Options.defaultWriteOptions,
      ...options
    };
    return this.write(writeOptions, batch);
  }

  del(key, options) {
    const batch = new _WriteBatch.WriteBatch();
    batch.del(key);
    const writeOptions = { ..._Options.defaultWriteOptions,
      ...options
    };
    return this.write(writeOptions, batch);
  }

  batch(batch, options) {
    const writeOptions = { ..._Options.defaultWriteOptions,
      ...options
    };
    return this.write(writeOptions, batch);
  }

  getSnapshot() {
    return this._snapshots.insert(this._versionSet.lastSequence);
  }

  releaseSnapshot(snapshot) {
    this._snapshots.delete(snapshot);
  }

  async write(options, batch) {
    if (!this._ok) await this.ok();
    const writer = new _WriterQueue.Writer();
    writer.batch = batch;
    this.writers.push(writer);

    while (this.writers.front() !== writer && !writer.done) {
      await writer.wait();
    }

    if (writer.done) {
      return;
    }

    const status = await this.makeRoomForWrite(!writer.batch);
    let lastWriter = writer;

    if ((await status.ok()) && !!writer.batch) {
      let lastSequence = this._versionSet.lastSequence;
      const [lastWriter_, batch] = this.buildBatchGroup();
      lastWriter = lastWriter_;

      _WriteBatch.WriteBatchInternal.setSequence(batch, lastSequence + 1n);

      lastSequence += BigInt(_WriteBatch.WriteBatchInternal.getCount(batch));
      await this._log.addRecord(new _Slice.default(_WriteBatch.WriteBatchInternal.getContents(batch)));

      _WriteBatch.WriteBatchInternal.insert(batch, this._memtable);

      if (batch === this.tmpBatch) this.tmpBatch.clear();
      this._versionSet.lastSequence = lastSequence;
    }

    while (true) {
      const front = this.writers.front();
      this.writers.popFront();

      if (front && front !== writer) {
        front.done = true;
        front.signal();
      }

      if (front === lastWriter) break;
    }

    if (this.writers.length > 0) {
      const front = this.writers.front();
      if (front) front.signal();
    }
  }

  buildBatchGroup() {
    const first = this.writers.front();
    if (!first) throw new Error(`writer is empty`);
    let result = first.batch;
    if (!result) throw new Error(`first batch is empty`);

    let size = _WriteBatch.WriteBatchInternal.byteSize(result);

    let maxSize = 1 << 20;
    const limit = 128 << 10;

    if (size <= limit) {
      maxSize = size + limit;
    }

    let lastWriter = first; // "1": Advance past "first"

    for (const writer of this.writers.iterator(1)) {
      if (writer.sync && !first.sync) {
        // Do not include a sync write into a batch handled by a non-sync write.
        break;
      }

      if (!!writer.batch) {
        size += _WriteBatch.WriteBatchInternal.byteSize(writer.batch);

        if (size > maxSize) {
          // Do not make batch too big
          break;
        }

        if (result === first.batch) {
          result = this.tmpBatch;
          (0, _DBHelper.assert)(_WriteBatch.WriteBatchInternal.getCount(result) === 0);

          _WriteBatch.WriteBatchInternal.append(result, first.batch);
        }

        _WriteBatch.WriteBatchInternal.append(result, writer.batch);
      }

      lastWriter = writer;
    }

    return [lastWriter, result];
  }
  /**
   * if force is true, force compact
   */


  async makeRoomForWrite(force) {
    let allowDelay = !force;
    let status = new _Status.default();

    while (true) {
      if (this._bgError) {
        status = this._bgError;
        break;
      } else if (allowDelay && this._versionSet.getNumLevelFiles(0) >= _Format.Config.kL0SlowdownWritesTrigger) {
        // We are getting close to hitting a hard limit on the number of
        // L0 files.  Rather than delaying a single write by several
        // seconds when we hit the hard limit, start delaying each
        // individual write by 1ms to reduce latency variance.  Also,
        // this delay hands over some CPU to the compaction thread in
        // case it is sharing the same core as the writer.
        if (this._options.debug) {
          this._options.log(`DEBUG level0 files >= slowdown trigger, wait 1s.`);
        }

        await new Promise(resolve => setTimeout(resolve, 1000));
        allowDelay = false;
      } else if (!force && this._memtable.size <= this._options.writeBufferSize) {
        // There is room in current memtable
        break;
      } else if (!!this._immtable) {
        // We have filled up the current memtable, but the previous
        // one is still being compacted, so we wait.
        this._options.log("Current memtable full; waiting...");
      } else if (this._versionSet.getNumLevelFiles(0) >= _Format.Config.kL0StopWritesTrigger) {
        // There are too many level-0 files.
        // TODO wait
        this._options.log("Too many L0 files; waiting...");
      } else {
        // 1. level0number < 12 and no immtable
        // 2. if (not force) level0number < 8 and memtable > 4MB
        // 3. if (force)
        // Attempt to switch to a new memtable and trigger compaction of old
        this._options.log("Attempt to switch to a new memtable and trigger compaction of old");

        (0, _DBHelper.assert)(this._versionSet.prevLogNumber === 0); // no logFile is compaction

        const newLogNumber = this._versionSet.getNextFileNumber();

        if (!!this._log) {
          await this._log.close();
          delete this._log;
        }

        this._log = new _LogWriter.default(await this._options.env.open((0, _Filename.getLogFilename)(this._dbpath, newLogNumber), "a"));
        this._immtable = this._memtable;
        this._memtable = new _MemTable.default(this._internalKeyComparator);

        this._memtable.ref();

        this._logFileNumber = newLogNumber;
        force = false;
        await this.maybeScheduleCompaction();
      }
    }

    return status;
  }

  async maybeScheduleCompaction() {
    if (this._options.debug) this._options.log(`DEBUG !this._immtable=${!this._immtable} !this._manualCompaction=${!this._manualCompaction} !this._versionSet.needsCompaction()=${!this._versionSet.needsCompaction()}`);

    if (this._backgroundCompactionScheduled) {
      // Already scheduled
      this._options.log("Already scheduled");
    } else if (this._bgError && !(await this._bgError.ok())) {
      // Already got an error; no more changes
      this._options.log("Already got an error; no more changes");
    } else if (!this._immtable && !this._manualCompaction && !this._versionSet.needsCompaction()) {
      // No work to be done
      this._options.log("No work to be done");
    } else {
      this._backgroundCompactionScheduled = true; // ignore: Env.Schedule, BGWork

      this._options.log("Background Compaction Scheduled");

      await this.backgroundCall();
    }
  }

  async backgroundCall() {
    (0, _DBHelper.assert)(this._backgroundCompactionScheduled);
    await this.backgroundCompaction();
    this._backgroundCompactionScheduled = false; // Previous compaction may have produced too many files in a level,
    // so reschedule another compaction if needed.

    await this.maybeScheduleCompaction();
  }

  async backgroundCompaction() {
    if (!!this._immtable) {
      this._options.log(`backgroundCompaction Compact MemTable and return`);

      await this.compactMemTable();
      return;
    }

    let compaction;
    let manualEnd = new _Format.InternalKey();

    if (!!this._manualCompaction) {
      const manual = this._manualCompaction;
      compaction = this._versionSet.compactRange(manual.level, manual.begin, manual.end);
      manual.done = !compaction;

      if (!!compaction) {
        manualEnd = compaction.inputs[0][compaction.numInputFiles(0) - 1].largest;
      } // Manual compaction ...


      if (this._options.debug) this._options.log("DEBUG Manual compaction ...");
    } else {
      // is not manual compaction
      compaction = this._versionSet.pickCompaction();
    }

    let status = new _Status.default();

    if (!compaction) {
      this._options.log(`backgroundCompaction no compaction`);
    } else if (!this._manualCompaction && compaction.isTrivialMove()) {
      this._options.log(`backgroundCompaction isTrivialMove`);

      (0, _DBHelper.assert)(compaction.numInputFiles(0) === 1);
      const f = compaction.inputs[0][0];
      compaction.edit.deleteFile(compaction.level, f.number);
      compaction.edit.addFile(compaction.level + 1, f.number, f.fileSize, f.smallest, f.largest);
      status = await this._versionSet.logAndApply(compaction.edit);
    } else {
      this._options.log(`backgroundCompaction doCompactionWork`);

      const compact = new _Compaction.CompactionState(compaction);
      const status = await this.doCompactionWork(compact);

      if (!(await status.ok())) {
        await this.recordBackgroundError(status);
      }

      await this.cleanupCompaction(compact);
      compaction.releaseInputs();
      await this.deleteObsoleteFiles();
    }

    if (await status.ok()) {
      this._options.log(`Compaction success...`);
    } else {
      this._options.log(`Compaction error...`);
    }

    if (!!this._manualCompaction) {
      const m = this._manualCompaction;

      if (!(await status.ok())) {
        m.done = true;
      }

      if (!m.done) {
        // We only compacted part of the requested range.  Update *m
        // to the range that is left to be compacted.
        m.tmpStorage = manualEnd;
        m.begin = m.tmpStorage;
      }

      delete this._manualCompaction;
    }
  } // major compaction


  async doCompactionWork(compact) {
    const startTime = this._options.env.now();

    let immTime = 0; // Time spent doing imm_ compactions

    this._options.log("Compacting files...");

    (0, _DBHelper.assert)(this._versionSet.getNumLevelFiles(compact.compaction.level) > 0);
    (0, _DBHelper.assert)(!compact.builder);
    (0, _DBHelper.assert)(!compact.outfile);

    if (this._snapshots.isEmpty()) {
      compact.smallestSnapshot = this._versionSet.lastSequence;
    } else {
      compact.smallestSnapshot = this._snapshots.oldest().sequenceNumber;
    }

    let status = new _Status.default();
    const ikey = new _Format.ParsedInternalKey();
    const currentUserKey = new _Slice.default();
    let hasCurrentUserKey = false;
    let lastSequenceForKey = _Format.InternalKey.kMaxSequenceNumber;
    if (this._options.debug) this._options.log(`DEBUG doCompactionWork before make input iterator`);

    for await (const input of this._versionSet.makeInputIterator(compact.compaction)) {
      if (!!this._immtable) {
        const immStartTime = this._options.env.now();

        await this.compactMemTable();
        immTime += this._options.env.now() - immStartTime;
      }

      const key = input.key;
      const shouldStopBefore = compact.compaction.shouldStopBefore(key);

      if (shouldStopBefore && !!compact.builder) {
        status = await this.finishCompactionOutputFile(compact, status);

        if (!(await status.ok())) {
          this._options.log(`Break because finishCompactionOutputFile fail ${status.message() || "-"}`);

          break;
        }
      }

      let drop = false;

      if (!(0, _Format.parseInternalKey)(key, ikey)) {
        currentUserKey.clear();
        hasCurrentUserKey = false;
        lastSequenceForKey = _Format.InternalKey.kMaxSequenceNumber;
      } else {
        if (!hasCurrentUserKey || this.userComparator.compare(ikey.userKey, currentUserKey) !== 0) {
          // First occurrence of this user key
          currentUserKey.buffer = ikey.userKey.buffer;
          hasCurrentUserKey = true;
          lastSequenceForKey = _Format.InternalKey.kMaxSequenceNumber;
        }

        if (lastSequenceForKey <= compact.smallestSnapshot) {
          // Hidden by an newer entry for same user key
          drop = true; // (A)
        } else if (ikey.valueType === _Format.ValueType.kTypeDeletion && ikey.sn <= compact.smallestSnapshot && compact.compaction.isBaseLevelForKey(ikey.userKey)) {
          // For this user key:
          // (1) there is no data in higher levels
          // (2) data in lower levels will have larger sequence numbers
          // (3) data in layers that are being compacted here and have
          //     smaller sequence numbers will be dropped in the next
          //     few iterations of this loop (by rule (A) above).
          // Therefore this deletion marker is obsolete and can be dropped.
          drop = true;
        }

        lastSequenceForKey = ikey.sn;
      } // used for debug
      // if (
      //   this._options.debug &&
      //   ikey.valueType === ValueType.kTypeDeletion &&
      //   !drop
      // ) {
      //   const snValueBig =
      //     ikey.sn.value > compact.smallestSnapshot
      //       ? 'key sequence is bigger then compact.smallestSnapshot. '
      //       : ''
      //   const isNotBaseLevel = !compact.compaction.isBaseLevelForKey(
      //     ikey.userKey
      //   )
      //     ? 'this level is not base level for key. '
      //     : ''
      //   const becauseMsg = !drop ? `Because ${snValueBig}${isNotBaseLevel}` : ''
      //   this._options.log(
      //     `${ikey.userKey} has been delete = ${drop}; ${becauseMsg}`
      //   )
      // }


      if (!drop) {
        // Open output file if necessary
        if (!compact.builder) {
          status = await this.openCompactionOutputFile(compact);

          if (!(await status.ok())) {
            this._options.log(`Break because openCompactionOutputFile fail ${status.message() || "-"}`);

            break;
          }
        }

        if (compact.builder.numEntries == 0) {
          compact.currentOutput().smallest.decodeFrom(key);
        }

        compact.currentOutput().largest.decodeFrom(key);
        await compact.builder.add(key, input.value); // Close output file if it is big enough

        if (compact.builder.fileSize >= compact.compaction.maxOutputFilesize) {
          status = await this.finishCompactionOutputFile(compact, new _Status.default());

          if (!(await status.ok())) {
            this._options.log(`Break because finishCompactionOutputFile2 fail ${status.message() || "-"}`);

            break;
          }
        }
      }
    }

    if ((await status.ok()) && !!compact.builder) {
      status = await this.finishCompactionOutputFile(compact, status);
    }

    const stats = new _Compaction.CompactionStats();
    stats.times = this._options.env.now() - startTime - immTime;

    for (let which = 0; which < 2; which++) {
      for (let i = 0; i < compact.compaction.numInputFiles(which); i++) {
        stats.bytesRead += compact.compaction.inputs[which][i].fileSize;
      }
    }

    for (let i = 0; i < compact.outputs.length; i++) {
      stats.bytesWritten += compact.outputs[i].fileSize;
    }

    this._stats[compact.compaction.level + 1].add(stats);

    if (await status.ok()) {
      status = await this.installCompactionResults(compact);
    } // TODO log level summary


    this._options.log(`compacted to: ${this._versionSet.getLevelSummary()}`);

    return status;
  }

  async compactMemTable() {
    (0, _DBHelper.assert)(!!this._immtable); // Save the contents of the memtable as a new Table

    const edit = new _VersionEdit.default();
    const base = this._versionSet.current;
    base.ref();
    let s = await this.writeLevel0Table(this._immtable, edit, base);
    base.unref(); // Replace immutable memtable with the generated Table

    if (await s.ok()) {
      edit.prevLogNumber = 0;
      edit.logNumber = this._logFileNumber; // Earlier logs no longer needed

      s = await this._versionSet.logAndApply(edit);
    }

    if (await s.ok()) {
      // Commit to the new state
      (0, _DBHelper.assert)(!!this._immtable);

      this._immtable.unref();

      delete this._immtable;
      await this.deleteObsoleteFiles();
    } else {
      this.recordBackgroundError(s);
    }
  }

  async writeLevel0Table(mem, edit, base) {
    if (mem.size === 0) return new _Status.default(Promise.resolve());

    const startTime = this._options.env.now();

    const meta = new _VersionFormat.FileMetaData();
    meta.fileSize = 0;
    meta.number = this._versionSet.getNextFileNumber();
    meta.largest = new _Format.InternalKey();
    this.pendingOutputs.add(meta.number);
    const status = await (0, _Builder.buildTable)(this._dbpath, this._options.env, this._options, mem.iterator(), meta);
    this.pendingOutputs.delete(meta.number); // Note that if file_size is zero, the file has been deleted and
    // should not be added to the manifest.

    let level = 0;

    if ((await status.ok()) && meta.fileSize > 0) {
      const minUserKey = meta.smallest.userKey;
      const maxUserKey = meta.largest.userKey;

      if (!!base) {
        level = base.pickLevelForMemTableOutput(minUserKey, maxUserKey);

        this._options.log(`Pick level=${level} for imm output`);
      }

      edit.addFile(level, meta.number, meta.fileSize, meta.smallest, meta.largest);
    }

    const stats = new _Compaction.CompactionStats();
    stats.times = this._options.env.now() - startTime;
    stats.bytesWritten = meta.fileSize;

    this._stats[level].add(stats);

    return status;
  }

  async openCompactionOutputFile(compact) {
    (0, _DBHelper.assert)(!!compact);
    (0, _DBHelper.assert)(!compact.builder);

    const fileNumber = this._versionSet.getNextFileNumber();

    this.pendingOutputs.add(fileNumber);
    const out = {};
    out.number = fileNumber;
    out.smallest = new _Format.InternalKey();
    out.largest = new _Format.InternalKey();
    compact.outputs.push(out);
    const tableFilename = (0, _Filename.getTableFilename)(this._dbpath, fileNumber);

    this._options.log(`Compaction output file number is ${fileNumber}`);

    const status = new _Status.default(this._options.env.open(tableFilename, "a+"));

    if (await status.ok()) {
      compact.outfile = await status.promise;
      compact.builder = new _SSTableBuilder.default(this._options, compact.outfile);
      if (this._options.debug) this._options.log("DEBUG open file success");
    } else {
      if (this._options.debug) this._options.log(`DEBUG open file error ${status.message || ""}`);
    }

    return status;
  }

  async installCompactionResults(compact) {
    this._options.log(`Compacted ${compact.compaction.numInputFiles(0)}@${compact.compaction.level} + ${compact.compaction.numInputFiles(1)}@${compact.compaction.level + 1} files => ${compact.totalBytes} bytes"`); // Add compaction outputs


    compact.compaction.addInputDeletions(compact.compaction.edit);
    const level = compact.compaction.level;
    if (this._options.debug) this._options.log(`DEBUG compact.outputs.length=${compact.outputs.length}`);

    for (let i = 0; i < compact.outputs.length; i++) {
      const out = compact.outputs[i];
      compact.compaction.edit.addFile(level + 1, out.number, out.fileSize, out.smallest, out.largest);
    }

    if (this._options.debug) this._options.log(`DEBUG installCompactionResults logAndApply starting...`);
    const status = await this._versionSet.logAndApply(compact.compaction.edit);

    if (!(await status.ok())) {
      if (this._options.debug) this._options.log(`DEBUG installCompactionResults fail`);
    } else {
      if (this._options.debug) this._options.log(`DEBUG installCompactionResults success`);
    }

    return status;
  }
  /**
   * manually compact
   */


  async compactRange(begin, end) {
    if (!this._ok) await this.ok();
    const sliceBegin = new _Slice.default(begin);
    const sliceEnd = new _Slice.default(end);
    let maxLevelWithFiles = 1;
    const base = this._versionSet._current;

    for (let level = 0; level < _Format.Config.kNumLevels; level++) {
      if (base.overlapInLevel(level, sliceBegin, sliceEnd)) {
        maxLevelWithFiles = level;
      }
    }

    await this.manualCompactMemTable();

    for (let level = 0; level < maxLevelWithFiles; level++) {
      await this.manualCompactRangeWithLevel(level, sliceBegin, sliceEnd);
    }
  }

  async manualCompactRangeWithLevel(level, begin, end) {
    if (this._options.debug) this._options.log(`DEBUG manualCompactRangeWithLevel ${level}...`);
    (0, _DBHelper.assert)(level >= 0);
    (0, _DBHelper.assert)(level + 1 < _Format.Config.kNumLevels);
    let beginStorage = new _Format.InternalKey();
    let endStorage = new _Format.InternalKey();
    const manual = {};
    manual.level = level;
    manual.done = false;

    if (!begin) {
      delete manual.begin;
    } else {
      beginStorage = new _Format.InternalKey(begin, _Format.InternalKey.kMaxSequenceNumber, _Format.kValueTypeForSeek);
      manual.begin = beginStorage;
    }

    if (!end) {
      delete manual.end;
    } else {
      endStorage = new _Format.InternalKey(end, 0n, _Format.ValueType.kTypeValue);
      manual.end = endStorage;
    }

    while (!manual.done) {
      if (!this._manualCompaction) {
        // Idle
        this._manualCompaction = manual;
        await this.maybeScheduleCompaction();
      } else {
        if (this._options.debug) this._options.log("DEBUG Running either my compaction or another compaction."); // Running either my compaction or another compaction.
      }
    }

    if (this._manualCompaction === manual) {
      // Cancel my manual compaction since we aborted early for some reason.
      delete this._manualCompaction;
    }
  }

  async manualCompactMemTable() {
    await this.write(_Options.defaultWriteOptions);
  }

  async recordBackgroundError(status) {
    this._options.log(status.message() || "recordBackgroundError");

    this._bgError = status;
  }

  async cleanupCompaction(compact) {
    if (!!compact.builder) {
      await compact.builder.abandon();
      delete compact.builder;
    } else {
      (0, _DBHelper.assert)(!compact.outfile);
    }

    delete compact.outfile;

    for (let i = 0; i < compact.outputs.length; i++) {
      const out = compact.outputs[i];
      this.pendingOutputs.delete(out.number);
    }
  }

  async deleteObsoleteFiles() {
    const live = this.pendingOutputs;

    this._versionSet.addLiveFiles(live);

    const filenames = (await this._options.env.readdir(this._dbpath)).reduce((filenames, dirent) => {
      if (dirent.isFile()) {
        filenames.push(dirent.name);
      }

      return filenames;
    }, []);
    const filesToDelete = [];

    for (const filename of filenames) {
      const internalFile = (0, _Filename.parseFilename)(filename);
      const number = internalFile.number;
      const type = internalFile.type;

      if (internalFile.isInternalFile) {
        let keep = true;

        switch (type) {
          case _Format.FileType.kLogFile:
            keep = number >= this._versionSet.logNumber || number === this._versionSet.prevLogNumber;
            break;

          case _Format.FileType.kDescriptorFile:
            // Keep my manifest file, and any newer incarnations'
            // (in case there is a race that allows other incarnations)
            keep = number >= this._versionSet.manifestFileNumber;
            break;

          case _Format.FileType.kTableFile:
            keep = live.has(number);
            break;

          case _Format.FileType.kTempFile:
            // Any temp files that are currently being written to must
            // be recorded in pending_outputs_, which is inserted into "live"
            keep = live.has(number);
            break;

          case _Format.FileType.kCurrentFile:
          case _Format.FileType.kDBLockFile:
          case _Format.FileType.kInfoLogFile:
            keep = true;
            break;
        }

        if (!keep) {
          filesToDelete.push(filename);

          if (type == _Format.FileType.kTableFile) {// TODO this.tableCache.Evict(number)
          }

          this._options.log(`Delete type=${type} #${number}`);
        }
      }
    }

    for (const filename of filesToDelete) {
      await this._options.env.unlink(_DBHelper.path.resolve(this._dbpath, filename));
    }
  }

  async finishCompactionOutputFile(compact, inputStatus) {
    let status = new _Status.default();
    (0, _DBHelper.assert)(!!compact);
    (0, _DBHelper.assert)(!!compact.outfile);
    (0, _DBHelper.assert)(!!compact.builder);
    const outputNumber = compact.currentOutput().number;
    (0, _DBHelper.assert)(outputNumber !== 0);
    const currentEntries = compact.builder.numEntries;

    if (await inputStatus.ok()) {
      status = new _Status.default(compact.builder.finish());
      await status.ok();
    } else {
      await compact.builder.abandon();
    }

    const currentBytes = compact.builder.fileSize;
    compact.currentOutput().fileSize = currentBytes;
    compact.totalBytes += currentBytes;
    delete compact.builder;
    delete compact.outfile;

    if (currentEntries > 0) {
      status = new _Status.default(this._options.env.access((0, _Filename.getTableFilename)(this._dbpath, outputNumber)));

      if (await status.ok()) {
        this._options.log(`Generated table #${outputNumber}@${compact.compaction.level}: ${currentEntries} keys, ${currentBytes} bytes`);
      }
    }

    return status;
  }

}

exports.default = Database;
//# sourceMappingURL=Database.js.map